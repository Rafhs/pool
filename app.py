import streamlit as st
import time

# Importando nossos mÃ³dulos personalizados
from modules import sheets_connector, ai_handler

# --- CONFIGURAÃ‡ÃƒO DA PÃGINA ---
st.set_page_config(
    page_title="Rotas & Transportes",
    page_icon="ğŸšŒ",
    layout="centered",
    initial_sidebar_state="expanded"
)

# --- FUNÃ‡Ã•ES DE INTERFACE (UI) ---
def init_session_state():
    """Inicializa o histÃ³rico do chat se ele nÃ£o existir."""
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "OlÃ¡! ğŸ‘‹ Para onde vocÃª deseja ir hoje?"}
        ]
    if "gemini_history" not in st.session_state:
        st.session_state.gemini_history = []

def render_sidebar():
    """Renderiza a barra lateral simplificada."""
    with st.sidebar:
        st.image("https://cdn-icons-png.flaticon.com/512/3448/3448339.png", width=60)
        st.title("Central de Rotas")
        st.markdown("---")

        # Tenta carregar os dados e mostra status simples
        df = sheets_connector.load_data()

        if not df.empty:
            st.success("ğŸŸ¢ Sistema Online")
            st.caption(f"{len(df)} rotas disponÃ­veis.")
        else:
            st.error("ğŸ”´ Sistema Offline")
            st.caption("Verifique a conexÃ£o.")

        st.markdown("---")
        # BotÃ£o para resetar a conversa
        if st.button("ğŸ—‘ï¸ Nova Pesquisa", use_container_width=True):
            st.session_state.messages = []
            st.session_state.gemini_history = []
            st.rerun()

        return df

def type_writer_effect(text: str, placeholder):
    """Efeito visual de digitaÃ§Ã£o para a resposta da IA."""
    text_buffer = ""
    for chunk in text.split(' '): # Divide por espaÃ§os para manter palavras inteiras
        text_buffer += chunk + " "
        placeholder.markdown(text_buffer + "â–Œ")
        time.sleep(0.02)
    placeholder.markdown(text_buffer) # Remove o cursor final

# --- FLUXO PRINCIPAL ---
def main():
    init_session_state()
    df_transportes = render_sidebar()

    st.title("ğŸšŒ Agente de Viagens")
    st.caption("Pergunte sobre linhas, ruas ou pontos de referÃªncia.")

    # Se a planilha nÃ£o carregou, interrompe aqui para nÃ£o quebrar o resto
    if df_transportes.empty:
        st.warning("âš ï¸ O sistema estÃ¡ temporariamente indisponÃ­vel.")
        st.stop()

    # Prepara o texto base para a IA
    contexto_dados = sheets_connector.get_formatted_context(df_transportes)

    # Exibe o histÃ³rico da conversa na tela
    for msg in st.session_state.messages:
        avatar = "ğŸš" if msg["role"] == "assistant" else "ğŸ§‘â€ğŸ’¼"
        st.chat_message(msg["role"], avatar=avatar).write(msg["content"])

    # Captura a nova pergunta do usuÃ¡rio
    if prompt := st.chat_input("Digite sua dÃºvida..."):
        # Mostra a pergunta do usuÃ¡rio
        st.chat_message("user", avatar="ğŸ§‘â€ğŸ’¼").write(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        # Gera e mostra a resposta da IA
        with st.chat_message("assistant", avatar="ğŸš"):
            placeholder = st.empty()
            placeholder.markdown("ğŸ” *Buscando informaÃ§Ãµes...*")

            # Chama o Gemini
            full_response = ai_handler.get_gemini_response(
                st.session_state.gemini_history,
                contexto_dados,
                prompt
            )

            # Exibe com efeito
            type_writer_effect(full_response, placeholder)

            # Salva no histÃ³rico
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            st.session_state.gemini_history.append({"role": "user", "parts": [prompt]})
            st.session_state.gemini_history.append({"role": "model", "parts": [full_response]})

if __name__ == "__main__":
    main()